# Shopping Website with ChatGPT Assistant

A full-stack e-commerce application built with FastAPI and Streamlit, featuring a ChatGPT-powered assistant for product inquiries.

## ğŸš€ Features

- **Product Management**: Browse, search, and filter products
- **Shopping Cart**: Add/remove items, manage quantities
- **Order System**: Create and manage orders
- **User Authentication**: Secure login and registration
- **ChatGPT Assistant**: AI-powered product assistance
- **Favorites System**: Save and manage favorite products
- **User Churn Prediction**: Predict if a user will churn using a Random Forest model

## ğŸ›  Tech Stack

### Backend
- Python FastAPI
- MySQL Database
- Redis Caching
- Docker Containerization

### Frontend
- Streamlit UI
- Python
- OpenAI ChatGPT API

### Testing & Development Tools
- Postman (API testing)
- Beekeeper Studio (database management)

## ğŸ“‹ Prerequisites

- Docker and Docker Compose
- Python 3.9+
- OpenAI API Key
- Postman (for API testing)
- Beekeeper Studio (optional, for database management)

## ğŸ”§ Installation & Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd shopping_website_final_project
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```
   
3. **Start Docker containers**. Run these commands in sequence:
   ```bash
   # First, start the containers with the yaml configuration
    docker-compose -f docker-compose.yaml up
    
    # Then, rebuild and start in detached mode
    docker-compose up -d --build
   ```
   This will start:
   - MySQL database (port 3306)
   - Redis cache (port 6379)

## ğŸš€ Running the Application

1. **Start the FastAPI backend**
   ```bash
   uvicorn main:app --reload
   ```
   The API will be available at `http://localhost:8000`

2. **Start the Streamlit frontend**
   ```bash
   streamlit run .streamlit/app/Home.py
   ```
   The web interface will open automatically at `http://localhost:8501`

## ğŸ“Š Database Management

You can view and manage the database using Beekeeper Studio:

1. Open Beekeeper Studio
2. Connect to MySQL with these credentials:
   - Host: localhost
   - Port: 3306
   - User: user
   - Password: password
   - Database: main

## ğŸ¤– Using the ChatGPT Assistant

1. Navigate to the Chat Assistant page in the Streamlit UI
2. Enter your OpenAI API key in the sidebar
3. Start asking questions about products!

## ğŸ›  User Churn Prediction (Bonus Task)

This project includes a Random Forest model to predict if a user will churn. The model is trained using a CSV dataset located in resources/csv/user_churn_data.csv.

### ğŸ” How it Works:

- The model is trained on the dataset, with churned as the target column.
- Users can only access churn prediction if they are logged in.
- The trained model is stored in models/optimal_rf_model.joblib.
- The prediction is available through a Streamlit page.

### ğŸ›  Model Training and Prediction

The model_service.py contains the following key functions:

- train_and_save_model():
   - Trains a RandomForestClassifier using GridSearchCV to find the best hyperparameters.
   - Saves the best model to models/optimal_rf_model.joblib.
- get_or_train_model():
   - Loads the saved model if it exists.
   - Otherwise, it retrains and saves a new model.
- predict_user_churn(user_features: dict) -> int:
   - Accepts user features as input.
   - Predicts whether the user is likely to churn (1) or not (0).
- get_performance_metrics():
   - Evaluates the model using accuracy, recall, F1-score, confusion matrix, and classification report.

## ğŸ“ Project Structure

```
shopping_website_final_project/
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ pages/
â”‚       â””â”€â”€ Home.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ controller/
â”œâ”€â”€ exceptions/
â”œâ”€â”€ model/
â”œâ”€â”€ redisClient/
â”‚   â””â”€â”€ redis_client.py
â”œâ”€â”€ repository/
â”œâ”€â”€ resources/
â”‚   â””â”€â”€ db-migrations/
â”œâ”€â”€ service/
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ”„ Development Workflow

1. Make changes to the code
2. If you modify the database schema:
   - Update the migration files in `resources/db-migrations`
   - Restart the Docker containers:
     ```bash
     docker-compose down
     docker-compose up -d
     ```

3. For frontend changes:
   - The Streamlit interface will automatically reload
   - Access the UI at `http://localhost:8501`

4. For backend changes:
   - The FastAPI server will automatically reload
   - Access the API docs at `http://localhost:8000/docs`

## ğŸ›  Troubleshooting

- **Database Connection Issues**
  ```bash
  docker-compose down
  docker volume rm shopping_website_final_project_mysql-data
  docker-compose up -d
  ```

- **Redis Cache Issues**
  ```bash
  docker-compose restart redis
  ```

- **Streamlit Port Already in Use**
  ```bash
  lsof -i :8501
  kill -9 <PID>
  ```

## ğŸ” Security Notes

- Never commit your OpenAI API key
- Change default database credentials in production
- Use proper environment variables for sensitive data

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Contact
Have questions? Feel free to reach out:
- **Email**: arinapolianker@gmail.com
- **LinkedIn**: [Arina Polianker](https://www.linkedin.com/in/arina-polianker-ab423b227/)
- **GitHub**: [arinapolianker](https://github.com/arinapolianker)



"# shopping_website_final_project_with_bonus" 
